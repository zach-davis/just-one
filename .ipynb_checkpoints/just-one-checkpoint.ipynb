{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "Description from boardgamegeek.com: Just One is a cooperative party game in which you play together to discover as many mystery words as possible. Find the best clue to help your teammate. <b>Be unique, as all identical clues will be cancelled!</b>\n",
    "\n",
    "<br>\n",
    "\n",
    "A complete game is played over 13 cards. The goal is to get a score as close to 13 as possible. In case of a right answer, the players score 1 point. In case of wrong answer, they lose the current card as well as the top card of the deck. Thus losing 2 points. In case of lack of answer, the players only lose the current card, and therefore only 1 point.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "Heavily borrowed from Sebastian Theiler's [tutorial](https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries for general functioning of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import random\n",
    "import math\n",
    "# for embedding distances and plotting\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now getting word embeddings\n",
    "Using Wikipedia 2014 + Gigaword 5: (http://nlp.stanford.edu/data/glove.6B.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store embeddings\n",
    "embeddings_dict = {}\n",
    "# looping over each line of the glove file\n",
    "with open(\"../glove.6B/glove.6B.50d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22282 ,  0.078798, -1.1952  ,  0.072751], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test that it works\n",
    "embeddings_dict['counterfactual'][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:  word embedding\n",
    "# output: sorted list of closest words\n",
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_dict.keys(), \n",
    "                  key=lambda word: spatial.distance.euclidean(embeddings_dict[word], \n",
    "                                                              embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['failure',\n",
       " 'serious',\n",
       " 'result',\n",
       " 'risk',\n",
       " 'danger',\n",
       " 'fear',\n",
       " 'prevent',\n",
       " 'damage',\n",
       " 'suffer']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test that it works\n",
    "find_closest_embeddings(embeddings_dict['cause'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The game\n",
    "The game involves two phases:\n",
    "1. Generation of hints from the \"hinters\"\n",
    "2. Guess of the secret word by the \"guesser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a secret word, passes to arbitrary hint function that generates hints, eliminates duplicates, then to arbitrary guess function\n",
    "# outputs 1 if the guess matches the hint, 0 otherwise\n",
    "def just_one(secret_word, hint_fn, guess_fn, n_hinters):\n",
    "    # gathering hints\n",
    "    hints = []\n",
    "    for hinter in range(n_hinters):\n",
    "        hints.append(hint_fn(secret_word, n_hinters))\n",
    "    \n",
    "    # removing duplicates\n",
    "    surviving_hints = []\n",
    "    for hint in hints:\n",
    "        tmp = hints.count(hint)\n",
    "        if tmp == 1: surviving_hints.append(hint)\n",
    "            \n",
    "    # just for now so i can see what's going on\n",
    "    print(hints)\n",
    "    print(surviving_hints)\n",
    "    \n",
    "    # passing to the guesser\n",
    "    guess = guess_fn(surviving_hints, n_hinters)\n",
    "    return(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple functions to get the ball rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a random word\n",
    "def random_hinter(secret_word, n_hinters):\n",
    "    return(random.sample(embeddings_dict.keys(),1))\n",
    "\n",
    "# returns a random selection from the top 10 closest words\n",
    "def sort_hinter(secret_word, n_hinters):\n",
    "    tmp = find_closest_embeddings(embeddings_dict[secret_word])[:10]\n",
    "    return(random.choice(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guessers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guesses a random word\n",
    "def random_guesser(surviving_hints, n_hinters):\n",
    "    return(random.sample(embeddings_dict.keys(),1))\n",
    "\n",
    "# returns nearest neighbor to mean\n",
    "# ZD note: I'm not sure this is the right way to do this\n",
    "def nn_guesser(surviving_hints, n_hinter):\n",
    "    # 50-D embeddings\n",
    "    hints_array = np.empty((len(surviving_hints),50))\n",
    "    for ix in range(len(surviving_hints)):\n",
    "        hints_array[ix,:] = embeddings_dict[surviving_hints[ix]]\n",
    "    # finding the center of the hints and returning nearest neighbor\n",
    "    hint_mean = np.mean(hints_array, 0)\n",
    "    nearest_neighbors = find_closest_embeddings(hint_mean)\n",
    "    # making sure the guess isn't one of the hints\n",
    "    safe_guess = next(guess for guess in nearest_neighbors if guess not in surviving_hints)\n",
    "    return(safe_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['snake', 'rabbit', 'monster', 'monster', 'monster', 'rat', 'beast', 'pet']\n",
      "['snake', 'rabbit', 'rat', 'beast', 'pet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2020)\n",
    "secret_word = ''.join(random.sample(embeddings_dict.keys(),1))\n",
    "secret_word = 'cat'\n",
    "print(secret_word)\n",
    "a = just_one(secret_word, sort_hinter, nn_guesser, 8)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "What is the right thing to do?\n",
    "\n",
    "- compute probability of other people giving words, to have an expected distribution over mean word embeddings\n",
    "- hinter should factor in the probability of words getting deleted\n",
    "- build-up of norms? For example might be cool as a start to have hinter 1 always give the closest on dimensions 1-10, 2 on dimensions 11-20, etc. Later this could be learned\n",
    "\n",
    "Experiments\n",
    "\n",
    "- free responses in a group?\n",
    "- give a dictionary of, say, 100 words and let them choose from them?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
